# -*- coding: utf-8 -*-
"""Final Project - Nahisha Ashraf & Jessica Groyon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1umnDWmuq5V0zmjP_DIa-yF3cRfu12euK

### **Part I: Exploratory Data Analysis**
Objectives: Clean, summarize, and visualize the data using groupby, filter, and crosstab.
Required Tasks:
1. Handle missing values appropriately.
2. Use pd.crosstab() to show TSA eligibility by residence type and state/territory.
3. Use groupby() to calculate average repair amounts by state.
4. Create and interpret four charts:
* Bar chart: TSA eligibility rate by state/territory
* Histogram: Distribution of repairAmount
* Boxplot: repairAmount across residence types
* Analyst Choice: Now that you are familiar with the data - explore a variable of your choice - how might this effect TSA Eligability.
"""

#imports
import urllib.request
import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.impute import SimpleImputer

"""In this block of code we are importing all the necessary libraies needed to execute the following codes."""

#upload the CSV
url = "https://storage.googleapis.com/info_450/IndividualAssistanceHousingRegistrantsLargeDisasters%20(1).csv"

filename = "fema_disaster_data.csv"

print(f" Downloading {filename}...")
urllib.request.urlretrieve(url, filename)

"""This block of code is importing in the data set throughthe url. This method was used due to the csv file being to big and timing out with the runtime."""

!pip install pyspark -q
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count as spark_count

#Start Spark
spark = SparkSession.builder.appName("fema_disaster_data").getOrCreate()

#Load CSV into Spark DataFrame
spark_df = spark.read.option("header", "true").csv(filename, inferSchema=True)

print(f" Successfully loaded {spark_df.count():,} rows")

"""In this block of code we are starting the spark session and loading the CSV into the spark dataframe. After the csv is down downloading, it is now in our file library."""

df = pd.read_csv(filename)
#df.head()

"""Here, we are creating the data frame variable and assigning it to the data set."""

#1. Handle missing values appropriately.
df_typ = df[[
    'disasterNumber',
    'damagedCity',
    'damagedStateAbbreviation',
    'residenceType',
    'grossIncome',
    'tsaEligible',
    'repairAmount',
    'destroyed',
    'waterLevel',
    'specialNeeds'
]]

df_typ = df_typ.copy() #used ai to fix bc it wasnt loading
numeric_cols = ["grossIncome", "repairAmount", "destroyed", "waterLevel", "specialNeeds"]
for col in numeric_cols:
    df_typ[col] = pd.to_numeric(df_typ[col], errors='coerce')
df_typ[numeric_cols] = df_typ[numeric_cols].fillna(0)

"""To prepare the dataset for analysis, we first selected only the variables required for the FEMA project, including disasterNumber, damagedCity, damagedStateAbbreviation, residenceType, grossIncome, tsaEligible, repairAmount, destroyed, waterLevel, and specialNeeds. Some fields that were numeric, including grossIncome, repairAmount, destroyed, and waterLevel, and specialNeeds were stored as strings, so we converted them to numeric values using errors='coerce.' This turns non-numeric values into missing data. Following the project guidelines to avoid dropping rows unnecessarily, we filled all missing numeric values with 0. This helps preserve the full dataset while ensuring consistency during our analysis.

When doing the numeric conversion, we used AI for help due to an error appearing and not excuting and converting the columns.
"""

df_typ.head()

#2. Use pd.crosstab() to show TSA eligibility by residence type and state/territory.

cross_tab = pd.crosstab(df_typ["residenceType"],[df_typ["damagedStateAbbreviation"], df_typ["tsaEligible"]])

cross_tab.head()

"""For this line of code, the cross tab is displaying the amount of applicants that fall within the combonation of residence types, states, and TSA eligibility. The outputted dataframe illustrates the elgibility varations for those in different residence types and by their state. After viewing this dataframe, we can easily see and compare which housing types in what state have the most TSA eligibility counts as well as the most non-eligible counts. Analyst are able to view trends and patterns for what may be causing those are eligible and non-eligble."""

#3. Use groupby() to calculate average repair amounts by state.
avg_repair_by_state = df_typ.groupby("damagedStateAbbreviation")["repairAmount"].mean().sort_values(ascending=False)

avg_repair_by_state.head()

"""This line of code compares repair assistance across locations using groupby() to calculate the average repairAmount for each state or territory. Grouping by damagedStateAbbreviation allowed us to summarize how much repair aid households received on average in each area. Sorting the results from highest to lowest helped highlight which states experienced the most severe damages, with Texas with the highest average of about $738, followed by North Carolina at $501.
These differences suggest that some states experienced more severe or costly damage than others, which may influence the level of assistance households received.
"""

#4. Create and interpret four charts:
#• Bar chart: TSA eligibility rate by state/territory
tsa_by_state = (
    df.groupby("damagedStateAbbreviation", as_index=False)["tsaEligible"]
      .mean()
      .rename(columns={"tsaEligible": "tsaRate"})
)

plt.bar(tsa_by_state["damagedStateAbbreviation"], tsa_by_state["tsaRate"])
plt.title("Bar Chart: TSA Eligibility by State")
plt.xlabel("State / Territory")
plt.ylabel("Eligibility Rate (Mean of tsaEligible)")
plt.show()

#• Histogram: Distribution of repairAmount
plt.hist(df_typ["repairAmount"], bins =10)
plt.title("Distribution of Repair Amount")
plt.xlabel("Repair Amount")
plt.ylabel("Frequency")
plt.show()

#• Boxplot: repairAmount across residence types
plt.figure(figsize=(18, 10))
sns.boxplot(data=df_typ, x='residenceType', y='repairAmount')
plt.xticks(rotation=45)
plt.title('Repair Amount by Residence Type')
plt.xlabel('Residence Type')
plt.ylabel('Repair Amount ($)')
plt.show()


#• Analyst Choice: Now that you are familiar with the data - explore a variable of your choice - how might this effect TSA Eligability.

#TSA-eligibility rate by whether home was destroyed
destroy_rate = (
    df_typ.groupby("destroyed")["tsaEligible"]
          .mean()
          .reset_index()
          .rename(columns={"tsaEligible": "tsaRate"})
)

destroy_rate

#bar chart for destory rate and tsa-elibility

plt.bar(destroy_rate["destroyed"], destroy_rate["tsaRate"])
plt.title("TSA Eligibility Rate by Destroyed Status")
plt.xlabel("Home Destroyed (0 = No, 1 = Yes)")
plt.ylabel("Eligibility Rate")
plt.xticks([0, 1])
plt.ylim(0, 1)
plt.show()

#analysis written below

"""In this block of code we are displaying our comparisons through bar charts, histograms, and boxplots. Due to the imense amount of data, we tried sampled the size down to a smaller number so that the box plot is able to display less outliers. However, the boxplot remained as its condensed look. For the charts we used the matplotlib since it is straightforward and easy to layout components of the chart such as the axises and lables.

Analyst Choice: Now that you are familiar with the data - explore a variable of your choice - how might this effect TSA Eligability.
* For our choices, we decided to explore the difference in TSA-eligibility between detroyed and non-destroyed homes. From this, we can see that the homes that were destroyed have a higher TSA-eligibility rate. This reflect's FEMA's mission of supporting individuals whose homes are not livable.

### **Part II: Inferential Statistics**
Compute and interpret confidence intervals and hypothesis tests.
1. Construct a 95% confidence interval for mean repairAmount of TSA-eligible vs. non-eligible
households.
2. Compare means between two states or territories.
3. Perform two-sample t-tests for these comparisons.
4. Interpret results clearly in plain language.
"""

#Construct a 95% confidence interval for mean repairAmount of TSA-eligible
import scipy.stats as stats

tsa_yes = df[df["tsaEligible"] == 1]["repairAmount"]
x_bar_yes = tsa_yes.mean()
sd_yes = tsa_yes.std()
n_yes = len(tsa_yes)

#standard error
sem_yes = sd_yes / (n_yes ** 0.5)

# 95% confidence interval using t-distribution
ci_yes = stats.t.interval(0.95, n_yes - 1, loc=x_bar_yes, scale=sem_yes)

print("95% CI for TSA Eligible is:", ci_yes[0], "to", ci_yes[1])

"""We began the confidence interval analysis by splitting the dataset into two groups: TSA-eligible households (coded as 1, or “yes”) and non-eligible households (coded as 0, or “no”). This allowed us to calculate separate confidence intervals for each group so we could compare the average repairAmount between those who qualified for TSA assistance and those who did not. For the TSA-eligible group, the 95% confidence interval ranged from approximately $5,943 to $5,961, providing an estimate of the average repair costs among applicants who received temporary shelter assistance."""

#Construct a 95% confidence interval for mean repairAmount of TSA-non-eligible
import scipy.stats as stats

tsa_no = df[df["tsaEligible"] == 0]["repairAmount"]
x_bar_no = tsa_no.mean()
sd_no = tsa_no.std()
n_no = len(tsa_no)

#standard error
sem_no = sd_no / (n_no ** 0.5)

# 95% confidence interval using t-distribution
ci_no = stats.t.interval(0.95, n_no - 1, loc=x_bar_no, scale=sem_no)

print("95% CI for TSA NON-Eligible is:", ci_no[0], "to", ci_no[1])

"""For TSA non-eligible households, the 95% confidence interval for the mean repairAmount ranges from approximately $4,869 to $4,880. This interval provides an estimate of the average repair costs among applicants who did not qualify for TSA assistance. Comparing this to the TSA-eligible confidence interval shows that eligible households generally reported higher repair needs, which may be why they were more likely to receive temporary shelter assistance."""

#Compare means between two states or territories.
state_one = "NC"
state_two = "FL"

#filter repair amounts for both states
repair_a = df_typ[df_typ["damagedStateAbbreviation"] == state_one]["repairAmount"].dropna()
repair_b = df_typ[df_typ["damagedStateAbbreviation"] == state_two]["repairAmount"].dropna()

print("The mean for NC is:", repair_a.mean())
print("The mean for FL is:", repair_b.mean())

"""After creating new variables to represent mean of the selected states for their repair amounts, NC and FL, we saw noticable differences. North Carolina has a higher average repair amount of $500.74

whereas Florida has an average of $90.60. From this data, we are able to interpret that North Carolina residents have claimed more damaged caused to their homes on average, which reports back as costly property damage. The differences can be explained by the geographic locations and their own weather patters for where these severities. Essentially, NC would require more FEMA support.
"""

#3. Perform two-sample t-tests for these comparisons.
t_stat, p_val = stats.ttest_ind(repair_a, repair_b, equal_var=False)
print("The t_stat is:",t_stat, "and the p-value is:", p_val)

"""We ran a two-sample t-test using equal_var=False to compare repair amounts between North Carolina and Florida. This method accounts for the states having different variances. The test produced a very large t-statistic and a p-value of 0, showing that the difference in their average repairAmount is statistically significant, meaning NC and FL have different repair needs.

**4. Interpret results clearly in plain language.**

We began by splitting the dataset into TSA-eligible and non-eligible households and calculating separate confidence intervals for each group. TSA-eligible applicants had a higher 95% confidence interval for repairAmount (about $5,943–$5,961), while non-eligible applicants had a lower interval (about $4,869–$4,880), showing that eligible households reported more severe damage on average. We then compared repair amounts between North Carolina and Florida and found a big difference: NC’s average repairAmount was about 500.74 dollars , while Florida’s was only 90.60 dollars. This suggests that NC applicants experienced more substantial property damage, potentially increasing their need for FEMA assistance. Finally, a two-sample t-test confirmed that the difference between the two states is statistically significant, meaning NC and FL truly face different levels of repair needs.

### **Part III: Predictive Modeling**
Build two models to predict TSA eligibility.
1. Select predictors such as grossIncome, repairAmount, destroyed, waterLevel, residenceType,
and damagedStateAbbreviation.
2. Encode categorical variables and split the dataset into train/test sets.
3. Train a Decision Tree Classifier and a Random Forest Classifier.
4. Compare accuracy, precision, recall, and confusion matrices.
5. Discuss which model generalizes best
"""

#Select predictors such as grossIncome, repairAmount, destroyed, waterLevel, residenceType,and damagedStateAbbreviation.
df_model = df_typ.sample(n=10000, random_state=42) #made it smaller so that it could load the decision trees without timing out

X = df_model.drop("tsaEligible", axis=1)
y = df_model["tsaEligible"]
y.head()

"""We began this portion of the code with selecting key predictor variables such as income, repairAmount, destroyed status, waterLevel, residenceType, and state because these features logically relate to TSA eligibility. To keep the modeling process fast and prevent the Decision Tree and Random Forest from timing out with the rutime, we randomly sampled 10,000 rows from the full dataset, which still provides a large and representative subset. We then separated the data into X (the predictors) and y (the outcome variable, tsaEligible). This is done so that the models could learn patterns is able to know the tsa-eligible from non-eligible applicants. After Looking at y.head(), we see that it confirms that the target variable contains both 0s and 1s, meaning our sample includes a mix of eligible and non-eligible cases."""

#numerical and categorical variables & preprocessor
numeric_features = ["grossIncome","repairAmount","destroyed","waterLevel","specialNeeds"]
categorical_features = ["residenceType","damagedStateAbbreviation"]

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder

preprocessor = ColumnTransformer([
        ("num", MinMaxScaler(), numeric_features),
        ("cat", OneHotEncoder(drop="first"), categorical_features)

])

preprocessor

"""To prepare the data for modeling, we separated the predictors into numeric features (such as income, repairAmount, and waterLevel) and categorical features (residence type and state). We then created a preprocessing pipeline using ColumnTransformer. The numeric variables are scaled with MinMaxScaler so they are on the same 0–1 range, which helps the model treat all numeric inputs equally. The categorical variables are converted into dummy variables using OneHotEncoder, with drop="first" to avoid creating redundant columns. This preprocessing step ensures that both numeric and categorical data are properly formatted and ready for the machine learning models."""

#test/train split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)

print("Training_rows: ", X_train.shape[0])
print("Testing_rows: ", X_test.shape[0])

"""We used train_test_split() to divide our dataset into a training set and a testing set, which is an essential step for evaluating how well a model generalizes to new, unseen data. By choosing a 70/30 split, the model is trained on 7,000 rows and tested on 3,000 rows, giving it enough data to learn patterns while still reserving a fair amount for evaluation. Setting random_state=42 ensures that the split is reproducible each time the code is run. The printed output confirms that the data was split correctly and that our model will be trained and tested on appropriately sized subsets of the sample."""

#Decision Tree
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier

model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", DecisionTreeClassifier(max_depth=5, random_state=42))
])

model.fit(X_train, y_train)

"""To build the Decision Tree model, we created a pipeline that combines the preprocessing steps with the classifier. The pipeline first applies the ColumnTransformer, which scales all numeric features using MinMaxScaler and encodes all categorical features with OneHotEncoder. After the data is cleaned and transformed, it is passed directly into a DecisionTreeClassifier with a maximum depth of 5. Using a pipeline ensures that all preprocessing happens automatically during training and testing and keeps the workflow organized. We then fit the model using the training data so it could learn patterns related to TSA eligibility."""

#random forest
from sklearn.ensemble import RandomForestClassifier

rf_model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", RandomForestClassifier(
        n_estimators=50,   # smaller number of trees = faster
        random_state=42,
        n_jobs=-1
    ))
])

rf_model.fit(X_train, y_train)

#y_pred_rf = rf_model.predict(X_test)

#y_pred_rf

"""For this block of code, we created a Random Forest model using a Pipeline so that the data preprocessing steps such as scaling numeric features and encoding categorical variables are applied before training the classifier. The RandomForestClassifier was set to 50 trees to speed up computation while still capturing meaningful patterns in the data due to the long time when executing this block of code. We did try other samples of trees to see the quickest run time and 50 trees was enough to generate the random forest. By using the rf_model.fit(X_train, y_train), it was able to train the model on the training set in order for it to learn how different features relate to TSA eligibility. This can be used for later prediction and evaluation making sure it is properly trained and ready to classify eligibility on new data."""

#Compare accuracy, precision, recall, and confusion matrices.
from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(X_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""After reviewing the output, we are able to see that there is an overall accuracy of 77%. This essentially means generalizes fairly good enough to unseen data. The precision rate of 0.74 for the 0 (non-eligible) class and rate of .86 for the 1 (eligible) class shows that the model is very cautious when predicting someone as eligible and is usually right when it does. As for recall, there was a high rate for eligble classes meaning that the model misses man eligible applicants and can raise fairness concerns. The F1-score reflects the models with good performance on detecting better on non-eligible people.

**5. Discuss which model generalizes best.**
* After analyzing and comparing the Decision Tree and Random Forest models, the Random Forest generalizes the best. The Random Forest tree displayed higher overall accuracy and stronger precision and recall within both classes. This essentially means that it makes more reliable predictions on new and unseen data. This occurs due to the Random Forest combining many trees rather than relying on just one, which the model be more stable. As for the Decision Tree, we see that it tended to overfit the training data and performed poorly on the test data.

### **Part IV: Streamlit Visualization and Dashboard**
Publish an interactive app that visualizes key insights.
Required Tasks:
1. Build a Streamlit app that displays:
• A Histogram of repairAmount.
• A Boxplot of repairAmount by tsaEligible.
2. Include titles, labels, and brief written insights.
3. Publish the app on Streamlit Cloud and include the public link in your report.
4. Provide a screenshot or embedded figure of your dashboard
"""

import streamlit as st
import pandas as pd
import plotly.express as px

st.title("FEMA Disaster Relief Dashboard")
st.write("Authors: Nahisha Ashraf & Jessica Groyon")

df = pd.read_csv("IndividualAssistanceHousingRegistrantsLargeDisasters.csv")

st.subheader("Data Preview")
st.write(df.head())

st.subheader("Histogram of Repair Amount")
fig_hist = px.histogram(df, x="repairAmount", nbins=30,
                        title="Distribution of Repair Amounts")
st.plotly_chart(fig_hist)

st.subheader("Boxplot: Repair Amount by TSA Eligibility")
fig_box = px.box(
    df,
    x="tsaEligible",
    y="repairAmount",
    title="Repair Amount by TSA Eligibility",
    labels={"tsaEligible": "TSA Eligible (1 = Yes, 0 = No)",
            "repairAmount": "Repair Amount"}
)
st.plotly_chart(fig_box)
